# AutoNotiSocial

Sistema de extracci√≥n de noticias de tecnolog√≠a/desarrollo, generaci√≥n de res√∫menes con IA, y preparaci√≥n para publicaci√≥n en redes sociales.

## üöÄ Caracter√≠sticas

- **Web Scraping**: Extrae noticias de sitios configurables (Dev.to, Hacker News, TechCrunch, etc.)
- **IA Multi-Provider**: Genera res√∫menes con Gemini o modelos locales (Ollama)
- **API REST**: Control completo del sistema v√≠a HTTP
- **Scheduler**: Ejecuci√≥n programada con cron expressions
- **SQLite**: Almacenamiento persistente de art√≠culos, res√∫menes y logs
- **Postman Collection**: Colecci√≥n lista para importar y probar

## üìã Requisitos

- Node.js 18+
- API Key de Google Gemini (o Ollama instalado localmente)

## üõ†Ô∏è Instalaci√≥n

```bash
# Clonar el repositorio
cd backend

# Instalar dependencias
npm install

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tu API key de Gemini

# Iniciar el servidor
npm start
```

## ‚öôÔ∏è Configuraci√≥n

Edita el archivo `.env`:

```env
# Puerto del servidor
PORT=3000

# Proveedor de IA: 'gemini' o 'ollama'
AI_PROVIDER=gemini

# API Key de Gemini
GEMINI_API_KEY=tu_api_key_aqui

# Ollama (opcional, para uso local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# Programaci√≥n de scraping (cada 6 horas por defecto)
SCRAPE_SCHEDULE=0 */6 * * *
```

## üîå API Endpoints

### Health
- `GET /api/health` - Estado del servidor

### Sources (Fuentes de noticias)
- `GET /api/sources` - Listar fuentes
- `POST /api/sources` - Crear fuente
- `PUT /api/sources/:id` - Actualizar fuente
- `DELETE /api/sources/:id` - Eliminar fuente
- `POST /api/sources/:id/scrape` - Ejecutar scraping manual

### Articles (Art√≠culos)
- `GET /api/articles` - Listar art√≠culos
- `GET /api/articles/:id` - Obtener art√≠culo con resumen
- `GET /api/articles/pending` - Art√≠culos sin resumen

### Summaries (Res√∫menes)
- `GET /api/summaries` - Listar res√∫menes
- `POST /api/summaries/generate/:articleId` - Generar resumen
- `POST /api/summaries/process-pending` - Procesar pendientes
- `PUT /api/summaries/:id` - Editar resumen

### Publications (Publicaciones)
- `GET /api/publications` - Historial
- `GET /api/publications/stats` - Estad√≠sticas
- `POST /api/publications` - Crear publicaci√≥n

### Scheduler
- `GET /api/scheduler/status` - Estado del scheduler
- `POST /api/scheduler/start` - Iniciar
- `POST /api/scheduler/stop` - Detener
- `POST /api/scheduler/run/:sourceId` - Ejecutar fuente manualmente

### Settings
- `GET /api/settings` - Ver configuraci√≥n
- `PUT /api/settings/ai-provider` - Cambiar proveedor de IA
- `POST /api/settings/ai/test` - Probar IA

### Logs
- `GET /api/logs` - Ver logs del sistema
- `GET /api/logs/stats` - Estad√≠sticas de logs

## üì¨ Postman

Importa la colecci√≥n desde `postman/AutoNotiSocial.postman_collection.json` para probar todos los endpoints.

## üóÑÔ∏è Base de Datos

SQLite con las siguientes tablas:

- **sources**: Fuentes de noticias configuradas
- **articles**: Art√≠culos scrapeados
- **summaries**: Res√∫menes generados por IA
- **publications**: Historial de publicaciones
- **system_logs**: Logs del sistema

## üìù Ejemplo de Uso

### 1. Agregar una fuente

```bash
curl -X POST http://localhost:3000/api/sources \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Dev.to",
    "url": "https://dev.to",
    "selectors": {
      "articleList": ".crayons-story",
      "title": ".crayons-story__title a"
    }
  }'
```

### 2. Ejecutar scraping manual

```bash
curl -X POST http://localhost:3000/api/sources/1/scrape
```

### 3. Generar resumen para un art√≠culo

```bash
curl -X POST http://localhost:3000/api/summaries/generate/1
```

### 4. Cambiar a Ollama (modelo local)

```bash
curl -X PUT http://localhost:3000/api/settings/ai-provider \
  -H "Content-Type: application/json" \
  -d '{"provider": "ollama"}'
```

## üîß Desarrollo

```bash
# Modo desarrollo con auto-reload
npm run dev
```

## üìÑ Licencia

MIT
