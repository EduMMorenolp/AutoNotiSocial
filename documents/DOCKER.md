# ğŸ³ Docker - DocumentaciÃ³n

GuÃ­a completa para ejecutar AutoNotiSocial con Docker.

## ğŸ“ Archivos de ConfiguraciÃ³n

```
AutoNotiSocial/
â”œâ”€â”€ docker-compose.yml    # Orquestador de servicios
â”œâ”€â”€ Dockerfile            # Imagen multi-stage
â”œâ”€â”€ nginx.conf            # ConfiguraciÃ³n del servidor web
â”œâ”€â”€ supervisord.conf      # Gestor de procesos
â”œâ”€â”€ start.sh              # Script de inicio
â”œâ”€â”€ .dockerignore         # Archivos excluidos del build
â””â”€â”€ .env.example          # Variables de entorno de ejemplo
```

## ğŸ—ï¸ Arquitectura del Contenedor

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Docker Container                         â”‚
â”‚                    (autonotisocial)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Nginx     â”‚  â”‚   Node.js   â”‚  â”‚       Ollama        â”‚  â”‚
â”‚  â”‚  (Frontend) â”‚  â”‚  (Backend)  â”‚  â”‚       (LLM)         â”‚  â”‚
â”‚  â”‚    :80      â”‚  â”‚   :3000     â”‚  â”‚      :11434         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚               â”‚                   â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                         â”‚                                   â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                  â”‚ Supervisor  â”‚                            â”‚
â”‚                  â”‚  (Gestor)   â”‚                            â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  VolÃºmenes:                                                 â”‚
â”‚  â€¢ ./data â†’ /app/backend/data (SQLite)                      â”‚
â”‚  â€¢ ./logs â†’ /app/backend/logs (Logs)                        â”‚
â”‚  â€¢ ollama_models â†’ /root/.ollama (Modelos LLM)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Inicio RÃ¡pido

### 1. Configurar Variables de Entorno

```bash
# Copiar archivo de ejemplo
cp .env.example .env

# Editar si es necesario (opcional, los valores por defecto funcionan)
nano .env
```

### 2. Construir y Ejecutar

```bash
# Construir imagen y ejecutar
docker-compose up --build

# Ejecutar en background
docker-compose up -d --build

# Ver logs
docker-compose logs -f
```

### 3. Acceder a la AplicaciÃ³n

| Servicio | URL | DescripciÃ³n |
|----------|-----|-------------|
| Frontend | http://localhost | Interfaz web |
| API | http://localhost/api | API REST |
| API (directo) | http://localhost:3000 | API sin proxy |
| Ollama | http://localhost:11434 | API de Ollama |

---

## ğŸ“‹ Comandos Ãštiles

### Docker Compose

```bash
# Iniciar servicios
docker-compose up -d

# Detener servicios
docker-compose down

# Reconstruir imagen
docker-compose build --no-cache

# Ver logs en tiempo real
docker-compose logs -f

# Ver estado
docker-compose ps

# Ejecutar comando en contenedor
docker-compose exec autonotisocial bash

# Reiniciar servicio
docker-compose restart
```

### GestiÃ³n de VolÃºmenes

```bash
# Ver volÃºmenes
docker volume ls

# Eliminar volumen de modelos (libera espacio)
docker volume rm autonotisocial_ollama_models

# Backup de base de datos
docker-compose exec autonotisocial cp /app/backend/data/database.sqlite /tmp/
docker cp autonotisocial:/tmp/database.sqlite ./backup/
```

### Ollama dentro del Contenedor

```bash
# Listar modelos instalados
docker-compose exec autonotisocial ollama list

# Descargar nuevo modelo
docker-compose exec autonotisocial ollama pull mistral

# Probar modelo
docker-compose exec autonotisocial ollama run llama3.2 "Hola, Â¿cÃ³mo estÃ¡s?"

# Ver modelo actual
docker-compose exec autonotisocial ollama show llama3.2
```

---

## âš™ï¸ ConfiguraciÃ³n Detallada

### docker-compose.yml

```yaml
version: '3.8'

services:
  autonotisocial:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: autonotisocial
    restart: unless-stopped
    ports:
      - "3000:3000"    # Backend
      - "80:80"        # Frontend
      - "11434:11434"  # Ollama
    environment:
      - NODE_ENV=production
      - PORT=3000
      - AUTO_START_SCHEDULER=true
      - AI_PROVIDER=${AI_PROVIDER:-ollama}
      - OLLAMA_URL=http://127.0.0.1:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2}
      - OLLAMA_PULL_MODEL=${OLLAMA_PULL_MODEL:-llama3.2}
    volumes:
      - ./data:/app/backend/data
      - ./logs:/app/backend/logs
      - ollama_models:/root/.ollama
    shm_size: '2gb'
    cap_add:
      - SYS_ADMIN
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

volumes:
  ollama_models:
```

### Variables de Entorno

| Variable | DescripciÃ³n | Default |
|----------|-------------|---------|
| `AI_PROVIDER` | Proveedor IA: `ollama` o `gemini` | `ollama` |
| `OLLAMA_MODEL` | Modelo a usar | `llama3.2` |
| `OLLAMA_PULL_MODEL` | Modelo a descargar al iniciar | `llama3.2` |
| `GEMINI_API_KEY` | API Key de Gemini | - |
| `AUTO_START_SCHEDULER` | Iniciar scheduler automÃ¡ticamente | `true` |

---

## ğŸ”§ Dockerfile Multi-Stage

El Dockerfile usa un build multi-stage para optimizar el tamaÃ±o:

### Stage 1: Build del Frontend
```dockerfile
FROM node:20-alpine AS frontend-builder
# Instala dependencias y ejecuta npm run build
# Resultado: /app/frontend/dist con archivos optimizados
```

### Stage 2: Imagen Final
```dockerfile
FROM node:20-slim
# Instala: Puppeteer deps, Nginx, Supervisor, Ollama
# Copia: frontend build, backend src
# Ejecuta: start.sh â†’ Supervisor
```

### Componentes Incluidos:
- **Node.js 20**: Runtime para el backend
- **Nginx**: Servidor web para el frontend
- **Chromium**: Para Puppeteer (web scraping)
- **Ollama**: LLM local
- **Supervisor**: Gestor de procesos

---

## ğŸŒ Nginx Configuration

```nginx
# Servir frontend SPA
location / {
    try_files $uri $uri/ /index.html;
}

# Proxy reverso para API
location /api {
    proxy_pass http://127.0.0.1:3000;
    proxy_http_version 1.1;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
}

# Cache de assets estÃ¡ticos
location ~* \.(js|css|png|jpg|svg)$ {
    expires 1y;
    add_header Cache-Control "public, immutable";
}
```

---

## ğŸ”’ Seguridad

### Headers de Seguridad (Nginx)
```nginx
add_header X-Frame-Options "SAMEORIGIN" always;
add_header X-Content-Type-Options "nosniff" always;
add_header X-XSS-Protection "1; mode=block" always;
```

### Capabilities de Docker
```yaml
cap_add:
  - SYS_ADMIN  # Requerido para Puppeteer sandbox
```

### Usuario No-Root
El backend se ejecuta como usuario `autonotisocial` para mayor seguridad.

---

## ğŸ’¾ Persistencia de Datos

| Volumen | Ruta en Contenedor | DescripciÃ³n |
|---------|-------------------|-------------|
| `./data` | `/app/backend/data` | Base de datos SQLite |
| `./logs` | `/app/backend/logs` | Archivos de log |
| `ollama_models` | `/root/.ollama` | Modelos de Ollama |

### Backup Completo

```bash
# Detener contenedor
docker-compose down

# Crear backup
tar -czvf backup-$(date +%Y%m%d).tar.gz data/ logs/

# Reiniciar
docker-compose up -d
```

---

## ğŸ› Troubleshooting

### El contenedor no inicia
```bash
# Ver logs de inicio
docker-compose logs -f

# Verificar que los puertos no estÃ©n ocupados
netstat -tulpn | grep -E "80|3000|11434"
```

### Ollama no descarga el modelo
```bash
# Descargar manualmente
docker-compose exec autonotisocial ollama pull llama3.2

# Verificar conexiÃ³n
docker-compose exec autonotisocial curl http://127.0.0.1:11434/api/tags
```

### Error de memoria
```bash
# Usar modelo mÃ¡s pequeÃ±o
OLLAMA_PULL_MODEL=llama3.2:1b docker-compose up -d
```

### Frontend no carga
```bash
# Verificar que nginx estÃ© corriendo
docker-compose exec autonotisocial supervisorctl status

# Ver logs de nginx
docker-compose exec autonotisocial cat /var/log/nginx/error.log
```
